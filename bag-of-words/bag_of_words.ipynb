{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFdOWq8ueM3Kq2tqjKYQg7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prajaktakini/Language-Models/blob/main/bag_of_words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Bag Of Words Implementation\n",
        "References:\n",
        "1. Medium Blog: https://medium.com/free-code-camp/an-introduction-to-bag-of-words-and-how-to-code-it-in-python-for-nlp-282e87a9da04\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "QXA_VnRxoKwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZbhUu9d4PvI",
        "outputId": "5d7a0013-7575-419d-ca36-d280597cf9e0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# All imports\n",
        "import string\n",
        "import numpy\n",
        "from typing import List\n",
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "4ve3iFvWpL4M"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns corpus of tokens for a given text\n",
        "def tokenize_text(text: list) -> List[str]:\n",
        "  words = []\n",
        "  for sentence in text:\n",
        "    tokenized_sentence = generate_tokens(sentence)\n",
        "    words.extend(tokenized_sentence)\n",
        "\n",
        "  # Sort all words in ASC order\n",
        "  words = sorted(list(set(words)))\n",
        "  return words\n"
      ],
      "metadata": {
        "id": "kxbngeDAy8z0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For a given sentence, generate tokens post pre-processing (Removes punctuation, stopwords, lowercases the words, etc)\n",
        "def generate_tokens(sentence: str) -> List[str]:\n",
        "  words = sentence.split()\n",
        "  stopwords_set = set(stopwords.words('english'))\n",
        "  tokens = [w.lower() for w in words if w not in string.punctuation and w.lower() for w in words if w not in stopwords_set]\n",
        "  return tokens\n"
      ],
      "metadata": {
        "id": "jzFthZi9zK55"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generates bag of words for given text\n",
        "def generate_bag_of_words(text: list):\n",
        "  words_corpus = tokenize_text(text)\n",
        "  print(f'Vocabulary \\n {words_corpus} \\n')\n",
        "\n",
        "  for sentence in text:\n",
        "    tokens = generate_tokens(sentence)\n",
        "\n",
        "    # Initialises BOW vector for a given sentence\n",
        "    encoded_vector = numpy.zeros(len(words_corpus))\n",
        "\n",
        "    for word in tokens:\n",
        "      for i, w in enumerate(words_corpus):\n",
        "        if word == w:\n",
        "          encoded_vector[i] += 1\n",
        "    print(\"{0} \\n{1}\\n\".format(sentence, numpy.array(encoded_vector)))"
      ],
      "metadata": {
        "id": "CbU_2vWC1IvK"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\"Various boroughs have made forward steps in the introduction of the cinematograph in the school\", \"The Birmingham Juvenile Organization Committee has prepared an exceedingly readable and interesting report for presentation to the Birmingham Education Committee\", \"To expand upon this theory, an open exhibition is to be arranged and will be attended by thousands of children from the senior departments of the schools, the younger element being excluded\",\n",
        "            \"Teachers and officials of the Local Education Authority will lend their support.\", \"A synopsis of prepared notes was given to the teachers and scholars\", \"The schools are to be formed into groups, so that pupils may attend a special performance at a convenient centre at regular intervals\", \"The programme of exhibition is to last for one hour; the films selected coming under five headings\"]\n",
        "\n",
        "generate_bag_of_words(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Enbk7XC93Ssm",
        "outputId": "aea30aaf-6014-4081-a4c1-2f1c04e67dc6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary \n",
            " ['a', 'arranged', 'attend', 'attended', 'authority', 'birmingham', 'boroughs', 'centre', 'children', 'cinematograph', 'coming', 'committee', 'convenient', 'departments', 'education', 'element', 'exceedingly', 'excluded', 'exhibition', 'expand', 'films', 'five', 'formed', 'forward', 'given', 'groups,', 'headings', 'hour;', 'interesting', 'intervals', 'introduction', 'juvenile', 'last', 'lend', 'local', 'made', 'may', 'notes', 'officials', 'one', 'open', 'organization', 'performance', 'prepared', 'presentation', 'programme', 'pupils', 'readable', 'regular', 'report', 'scholars', 'school', 'schools', 'schools,', 'selected', 'senior', 'special', 'steps', 'support.', 'synopsis', 'teachers', 'the', 'theory,', 'thousands', 'to', 'upon', 'various', 'younger'] \n",
            "\n",
            "Various boroughs have made forward steps in the introduction of the cinematograph in the school \n",
            "[ 0.  0.  0.  0.  0.  0. 15.  0.  0. 15.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0. 15.  0.  0.  0.  0.  0.  0. 15.  0.  0.  0.  0. 15.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 15.  0.  0.\n",
            "  0.  0.  0. 15.  0.  0.  0.  0.  0.  0.  0.  0. 15.  0.]\n",
            "\n",
            "The Birmingham Juvenile Organization Committee has prepared an exceedingly readable and interesting report for presentation to the Birmingham Education Committee \n",
            "[ 0.  0.  0.  0.  0. 40.  0.  0.  0.  0.  0. 40.  0.  0. 20.  0. 20.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 20.  0.  0. 20.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0. 20.  0. 20. 20.  0.  0. 20.  0. 20.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.]\n",
            "\n",
            "To expand upon this theory, an open exhibition is to be arranged and will be attended by thousands of children from the senior departments of the schools, the younger element being excluded \n",
            "[ 0. 32.  0. 32.  0.  0.  0.  0. 32.  0.  0.  0.  0. 32.  0. 32.  0. 32.\n",
            " 32. 32.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0. 32.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 32.\n",
            "  0. 32.  0.  0.  0.  0.  0.  0. 32. 32. 32. 32.  0. 32.]\n",
            "\n",
            "Teachers and officials of the Local Education Authority will lend their support. \n",
            "[ 0.  0.  0.  0. 12.  0.  0.  0.  0.  0.  0.  0.  0.  0. 12.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 12. 12.  0.\n",
            "  0.  0. 12.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0. 12.  0. 12.  0.  0.  0.  0.  0.  0.  0.]\n",
            "\n",
            "A synopsis of prepared notes was given to the teachers and scholars \n",
            "[12.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0. 12.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0. 12.  0.  0.  0.  0.  0. 12.  0.  0.  0.  0.  0.  0. 12.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0. 12. 12.  0.  0.  0.  0.  0.  0.  0.]\n",
            "\n",
            "The schools are to be formed into groups, so that pupils may attend a special performance at a convenient centre at regular intervals \n",
            "[ 0.  0. 23.  0.  0.  0.  0. 23.  0.  0.  0.  0. 23.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0. 23.  0.  0. 23.  0.  0.  0. 23.  0.  0.  0.  0.  0.  0.\n",
            " 23.  0.  0.  0.  0.  0. 23.  0.  0.  0. 23.  0. 23.  0.  0.  0. 23.  0.\n",
            "  0.  0. 23.  0.  0.  0.  0. 23.  0.  0.  0.  0.  0.  0.]\n",
            "\n",
            "The programme of exhibition is to last for one hour; the films selected coming under five headings \n",
            "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 17.  0.  0.  0.  0.  0.  0.  0.\n",
            " 17.  0. 17. 17.  0.  0.  0.  0. 17. 17.  0.  0.  0.  0. 17.  0.  0.  0.\n",
            "  0.  0.  0. 17.  0.  0.  0.  0.  0. 17.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            " 17.  0.  0.  0.  0.  0.  0. 17.  0.  0.  0.  0.  0.  0.]\n",
            "\n"
          ]
        }
      ]
    }
  ]
}